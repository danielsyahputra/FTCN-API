# this is the root setting of all setting and will be loaded in first place
# the loading sequence is root_setting -> specific setting
# -> manully overided setting -> computed setting  in finalize_config() 
# which means access config before finalize can be dangerous
# always remember to add a space after ":"

setting_name: base
data_mode: image 
# for better compatiable with philly and potential running enviroment
# all path under path should be rel_path w.r.t the config.py
# and the abspath will be compute when finalize

# python -m torch.distributed.launch  --nproc_per_node=2 main.py  --setting naive_raw.yaml
# --config trainer.default.log_step=1 trainer.default.sample_step=20
strategies: ["scale_mean","scale_0","scale_1","scale_2","scale_3"]
mask_direct: true

clip_size: 32

reg_weight: 1
class_weight: 1
final_weight: 1
model:
  inco:
    spatial_count: 0
    SOLVER: 
      BASE_LR: 0.1
      LR_POLICY: cosine
      MAX_EPOCH: 100
      MOMENTUM: 0.9
      WEIGHT_DECAY: 1e-4
      WARMUP_EPOCHS: 10
      WARMUP_START_LR: 0.01
      OPTIMIZING_METHOD: sgd
  transformer:
    patch_type: time
    stop_point: 5
    depth: 1

path:
 model_dir: ../checkpoint
 pretrain_dir: ../pretrain
 log_dir: ../checkpoint
 data_dir: host:lmdb_dir
 precomputed_dir: null

trainer_type: YL3DIncoPolicyS
dataset_type: YL_3D_INCO_BASE_ZIP_PNG_S
classifier_type: i3d_temporal_var_fix_dropout_tt_cfg

imsize: 224
base_count: 12
aug_in_train: true
test_on_train: true

next_frame_rate: 0.0
aug:
 min_size: 64
 max_size: 317
 min_quality: 60
 max_quality: 100
 need_img_degrade: false
 need_mask_distortion: true
 need_color_match: true
 max_step: 4
 compression: false
 cutout: 0
 earse: 1
 aug_prob: 0
 types: ["C23_NOISE"]
 earse_type: ["strong_black"]

dataset:
 real_train:
  original_c23: 1
 fake_train:
  NeuralTextures_c23: 1
  Face2Face_c23: 1
  FaceSwap_c23: 1
  Deepfakes_c23: 1
 aug_online:
  empty: 1
 tests:
  NeuralTextures_c23: ["NeuralTextures_c23"]
  Face2Face_c23: ["Face2Face_c23"]
  FaceSwap_c23: ["FaceSwap_c23"]
  Deepfakes_c23: ["Deepfakes_c23"]
  
max_to_keep: 100

data_source: lmdb

trainer:
 default:
  apex_option: O0
  batch_size: 16
  test_batch_size: 8
  model_save_step: 10000
  log_step: 200
  sample_step: 1000
  init_lr: 3e-4
  total_epoch: 1000
  one_test_step: 200
  detach_step: 5000
  validation_step: 10000
  freeze_backbone_step: 0
  total_step: 200000
  lr_step: 100000



#classifier:
# default:
#  pretrained: false